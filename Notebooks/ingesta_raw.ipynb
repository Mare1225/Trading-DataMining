{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f9fb233-d47a-442f-9612-436d76a618cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pipeline de Ingesta de Datos Financieros desde Yahoo Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "158032ba-f0ef-4a42-8e57-5be1e37b0c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yfinance\n",
      "  Downloading yfinance-0.2.66-py2.py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: sqlalchemy in /opt/conda/lib/python3.11/site-packages (2.0.22)\n",
      "Collecting psycopg2-binary\n",
      "  Downloading psycopg2_binary-2.9.11-cp311-cp311-manylinux2014_aarch64.manylinux_2_17_aarch64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /opt/conda/lib/python3.11/site-packages (from yfinance) (1.24.4)\n",
      "Requirement already satisfied: requests>=2.31 in /opt/conda/lib/python3.11/site-packages (from yfinance) (2.31.0)\n",
      "Collecting multitasking>=0.0.7 (from yfinance)\n",
      "  Downloading multitasking-0.0.12.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: platformdirs>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from yfinance) (3.11.0)\n",
      "Requirement already satisfied: pytz>=2022.5 in /opt/conda/lib/python3.11/site-packages (from yfinance) (2023.3.post1)\n",
      "Collecting frozendict>=2.3.4 (from yfinance)\n",
      "  Downloading frozendict-2.4.7-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting peewee>=3.16.2 (from yfinance)\n",
      "  Downloading peewee-3.18.3.tar.gz (3.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.11.1 in /opt/conda/lib/python3.11/site-packages (from yfinance) (4.12.2)\n",
      "Collecting curl_cffi>=0.7 (from yfinance)\n",
      "  Downloading curl_cffi-0.13.0-cp39-abi3-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: protobuf>=3.19.0 in /opt/conda/lib/python3.11/site-packages (from yfinance) (4.24.3)\n",
      "Collecting websockets>=13.0 (from yfinance)\n",
      "  Downloading websockets-15.0.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.11/site-packages (from sqlalchemy) (4.8.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.11/site-packages (from sqlalchemy) (3.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.11/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
      "Requirement already satisfied: cffi>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from curl_cffi>=0.7->yfinance) (1.16.0)\n",
      "Collecting certifi>=2024.2.2 (from curl_cffi>=0.7->yfinance)\n",
      "  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.31->yfinance) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.31->yfinance) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.31->yfinance) (2.0.7)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.21)\n",
      "Downloading yfinance-0.2.66-py2.py3-none-any.whl (123 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.4/123.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading psycopg2_binary-2.9.11-cp311-cp311-manylinux2014_aarch64.manylinux_2_17_aarch64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading curl_cffi-0.13.0-cp39-abi3-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (7.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading frozendict-2.4.7-py3-none-any.whl (16 kB)\n",
      "Downloading websockets-15.0.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (182 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.9/182.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.4/159.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: multitasking, peewee\n",
      "  Building wheel for multitasking (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for multitasking: filename=multitasking-0.0.12-py3-none-any.whl size=15548 sha256=b5c999c078567454d45ec4118d4627bdff2199181f5438d59af682d8ff811dd0\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/42/d6/84/bf57a755f4569494cd00de4bb46ef064874823f4d19c82e960\n",
      "  Building wheel for peewee (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for peewee: filename=peewee-3.18.3-cp311-cp311-linux_aarch64.whl size=312484 sha256=a344e1fc5c0b90d013794c987fca86f68f674c793e3126039f81bf2036f3199d\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/05/dc/94/4ba26d23cac9aee7481d3dfcc7e99ce2cc5731230ec10f7ec1\n",
      "Successfully built multitasking peewee\n",
      "Installing collected packages: peewee, multitasking, websockets, psycopg2-binary, frozendict, certifi, curl_cffi, yfinance\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2023.7.22\n",
      "    Uninstalling certifi-2023.7.22:\n",
      "      Successfully uninstalled certifi-2023.7.22\n",
      "Successfully installed certifi-2025.11.12 curl_cffi-0.13.0 frozendict-2.4.7 multitasking-0.0.12 peewee-3.18.3 psycopg2-binary-2.9.11 websockets-15.0.1 yfinance-0.2.66\n"
     ]
    }
   ],
   "source": [
    "!pip install yfinance sqlalchemy psycopg2-binary pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ccca74-5546-401e-8f1d-426bbdc108cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aec195f-229c-4742-8f17-00958aa9c42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from sqlalchemy import create_engine, text\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52330ec0-5947-4581-9133-911627a26d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descarga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "854de4d8-cb9d-4764-ba9d-918343dc8c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargando datos para IBM (Intento 1/4)...\n",
      "Filas IBM: 1496\n"
     ]
    }
   ],
   "source": [
    "TICKER = os.getenv('TICKER')\n",
    "START_DATE = os.getenv('START_DATE')\n",
    "END_DATE = os.getenv('END_DATE')\n",
    "end_dt = datetime.strptime(END_DATE, '%Y-%m-%d').date()\n",
    "\n",
    "max_retries = 4\n",
    "for attempt in range(max_retries):\n",
    "    try:\n",
    "        print(f\"Descargando datos para {TICKER} (Intento {attempt + 1}/{max_retries})...\")\n",
    "        df_raw = yf.download(\n",
    "            tickers=TICKER, \n",
    "            start=START_DATE, \n",
    "            end=end_dt + pd.Timedelta(days=1), \n",
    "            interval='1d',\n",
    "            progress=False,\n",
    "            auto_adjust=False\n",
    "        )\n",
    "\n",
    "        # Asegurar que las columnas no sean MultiIndex\n",
    "        if isinstance(df_raw.columns, pd.MultiIndex):\n",
    "            df_raw.columns = df_raw.columns.get_level_values(0)\n",
    "\n",
    "        df_raw.reset_index(inplace=True)\n",
    "        # Añadir columna ticker\n",
    "        df_raw['ticker'] = TICKER\n",
    "        print(f\"Filas {TICKER}: {len(df_raw)}\")\n",
    "        break  \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error al descargar {TICKER} (intento {attempt + 1}): {e}\")\n",
    "        time.sleep(5 * (attempt + 1))\n",
    "        if attempt == max_retries - 1:\n",
    "            print(f\"No se pudo descargar {TICKER} después de {max_retries} intentos.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c948b04b-48cc-4868-b52b-8a4306325363",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agregar metadatos\n",
    "df_raw['ingested_at_utc'] = datetime.utcnow()\n",
    "df_raw['run_id'] = datetime.now().strftime('run_%Y%m%d_%H%M')\n",
    "df_raw['source_name'] = 'yahoo_finance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2595c20-fed4-41f5-a555-263a35023950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estandarizácion de nombres "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7031e21a-7d92-4177-b08f-c69267c61b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas renombradas: ['date', 'adj_close', 'close', 'high', 'low', 'open', 'volume', 'ticker', 'ingested_at_utc', 'run_id', 'source_name']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "      <th>ingested_at_utc</th>\n",
       "      <th>run_id</th>\n",
       "      <th>source_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>100.013763</td>\n",
       "      <td>129.464630</td>\n",
       "      <td>129.942642</td>\n",
       "      <td>128.843216</td>\n",
       "      <td>129.063095</td>\n",
       "      <td>3293436</td>\n",
       "      <td>IBM</td>\n",
       "      <td>2025-12-14 00:42:43.575547</td>\n",
       "      <td>run_20251214_0042</td>\n",
       "      <td>yahoo_finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>99.216125</td>\n",
       "      <td>128.432129</td>\n",
       "      <td>128.929260</td>\n",
       "      <td>127.686424</td>\n",
       "      <td>127.695984</td>\n",
       "      <td>2482890</td>\n",
       "      <td>IBM</td>\n",
       "      <td>2025-12-14 00:42:43.575547</td>\n",
       "      <td>run_20251214_0042</td>\n",
       "      <td>yahoo_finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>99.038879</td>\n",
       "      <td>128.202682</td>\n",
       "      <td>128.336517</td>\n",
       "      <td>127.342255</td>\n",
       "      <td>127.552582</td>\n",
       "      <td>2537073</td>\n",
       "      <td>IBM</td>\n",
       "      <td>2025-12-14 00:42:43.575547</td>\n",
       "      <td>run_20251214_0042</td>\n",
       "      <td>yahoo_finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>99.105324</td>\n",
       "      <td>128.288712</td>\n",
       "      <td>129.024857</td>\n",
       "      <td>127.533463</td>\n",
       "      <td>127.810707</td>\n",
       "      <td>3232977</td>\n",
       "      <td>IBM</td>\n",
       "      <td>2025-12-14 00:42:43.575547</td>\n",
       "      <td>run_20251214_0042</td>\n",
       "      <td>yahoo_finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>99.932503</td>\n",
       "      <td>129.359467</td>\n",
       "      <td>129.885284</td>\n",
       "      <td>128.030594</td>\n",
       "      <td>128.594650</td>\n",
       "      <td>4545916</td>\n",
       "      <td>IBM</td>\n",
       "      <td>2025-12-14 00:42:43.575547</td>\n",
       "      <td>run_20251214_0042</td>\n",
       "      <td>yahoo_finance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   adj_close       close        high         low        open  \\\n",
       "0 2020-01-02  100.013763  129.464630  129.942642  128.843216  129.063095   \n",
       "1 2020-01-03   99.216125  128.432129  128.929260  127.686424  127.695984   \n",
       "2 2020-01-06   99.038879  128.202682  128.336517  127.342255  127.552582   \n",
       "3 2020-01-07   99.105324  128.288712  129.024857  127.533463  127.810707   \n",
       "4 2020-01-08   99.932503  129.359467  129.885284  128.030594  128.594650   \n",
       "\n",
       "    volume ticker            ingested_at_utc             run_id    source_name  \n",
       "0  3293436    IBM 2025-12-14 00:42:43.575547  run_20251214_0042  yahoo_finance  \n",
       "1  2482890    IBM 2025-12-14 00:42:43.575547  run_20251214_0042  yahoo_finance  \n",
       "2  2537073    IBM 2025-12-14 00:42:43.575547  run_20251214_0042  yahoo_finance  \n",
       "3  3232977    IBM 2025-12-14 00:42:43.575547  run_20251214_0042  yahoo_finance  \n",
       "4  4545916    IBM 2025-12-14 00:42:43.575547  run_20251214_0042  yahoo_finance  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = {\n",
    "    'Date': 'date',         # Columna generada por reset_index\n",
    "    'Open': 'open',\n",
    "    'High': 'high',\n",
    "    'Low': 'low',\n",
    "    'Close': 'close',\n",
    "    'Adj Close': 'adj_close',\n",
    "    'Volume': 'volume'\n",
    "}\n",
    "df_raw.columns = [mapping.get(col, str(col).lower()) for col in df_raw.columns]\n",
    "\n",
    "print(f\"Columnas renombradas: {df_raw.columns.tolist()}\")\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16f6ed4-f362-477c-b9aa-138c17d2d357",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Motor de SQLAlchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c653e25e-5609-472f-8aed-63ffa60f0057",
   "metadata": {},
   "outputs": [],
   "source": [
    "PG_USER = os.getenv('PG_USER')\n",
    "PG_PASSWORD = os.getenv('PG_PASSWORD')\n",
    "PG_HOST = os.getenv('PG_HOST')\n",
    "PG_PORT = os.getenv('PG_PORT')\n",
    "PG_DB = os.getenv('PG_DB')\n",
    "\n",
    "engine = create_engine(f\"postgresql://{PG_USER}:{PG_PASSWORD}@{PG_HOST}:{PG_PORT}/{PG_DB}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08dfd70-dbef-4f74-b441-111a9b4f7ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Días bursátiles sin datos (deben ser pocos y explicados)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f56f0ffd-64bf-46f2-b79b-2ffb442c4e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Falta el día: 2020-01-20\n",
      "  - Falta el día: 2020-02-17\n",
      "  - Falta el día: 2020-04-10\n",
      "  - Falta el día: 2020-05-25\n",
      "  - Falta el día: 2020-07-03\n",
      "  - Falta el día: 2020-09-07\n",
      "  - Falta el día: 2020-11-26\n",
      "  - Falta el día: 2020-12-25\n",
      "  - Falta el día: 2021-01-01\n",
      "  - Falta el día: 2021-01-18\n",
      "  - Falta el día: 2021-02-15\n",
      "  - Falta el día: 2021-04-02\n",
      "  - Falta el día: 2021-05-31\n",
      "  - Falta el día: 2021-07-05\n",
      "  - Falta el día: 2021-09-06\n",
      "  - Falta el día: 2021-11-25\n",
      "  - Falta el día: 2021-12-24\n",
      "  - Falta el día: 2022-01-17\n",
      "  - Falta el día: 2022-02-21\n",
      "  - Falta el día: 2022-04-15\n",
      "  - Falta el día: 2022-05-30\n",
      "  - Falta el día: 2022-06-20\n",
      "  - Falta el día: 2022-07-04\n",
      "  - Falta el día: 2022-09-05\n",
      "  - Falta el día: 2022-11-24\n",
      "  - Falta el día: 2022-12-26\n",
      "  - Falta el día: 2023-01-02\n",
      "  - Falta el día: 2023-01-16\n",
      "  - Falta el día: 2023-02-20\n",
      "  - Falta el día: 2023-04-07\n",
      "  - Falta el día: 2023-05-29\n",
      "  - Falta el día: 2023-06-19\n",
      "  - Falta el día: 2023-07-04\n",
      "  - Falta el día: 2023-09-04\n",
      "  - Falta el día: 2023-11-23\n",
      "  - Falta el día: 2023-12-25\n",
      "  - Falta el día: 2024-01-01\n",
      "  - Falta el día: 2024-01-15\n",
      "  - Falta el día: 2024-02-19\n",
      "  - Falta el día: 2024-03-29\n",
      "  - Falta el día: 2024-05-27\n",
      "  - Falta el día: 2024-06-19\n",
      "  - Falta el día: 2024-07-04\n",
      "  - Falta el día: 2024-09-02\n",
      "  - Falta el día: 2024-11-28\n",
      "  - Falta el día: 2024-12-25\n",
      "  - Falta el día: 2025-01-01\n",
      "  - Falta el día: 2025-01-09\n",
      "  - Falta el día: 2025-01-20\n",
      "  - Falta el día: 2025-02-17\n",
      "  - Falta el día: 2025-04-18\n",
      "  - Falta el día: 2025-05-26\n",
      "  - Falta el día: 2025-06-19\n",
      "  - Falta el día: 2025-07-04\n",
      "  - Falta el día: 2025-09-01\n",
      "  - Falta el día: 2025-11-27\n"
     ]
    }
   ],
   "source": [
    "min_date = df_raw['date'].min()\n",
    "max_date = df_raw['date'].max()\n",
    "\n",
    "full_days = pd.date_range(\n",
    "    start=min_date, \n",
    "    end=max_date, \n",
    "    freq='B' #Dias hábiles\n",
    ")\n",
    "\n",
    "df_dates = set(df_raw['date'].dt.normalize())\n",
    "missing_days = full_days[~full_days.isin(df_dates)]\n",
    "\n",
    "for day in missing_days:\n",
    "    print(f\"  - Falta el día: {day.strftime('%Y-%m-%d')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7fc863-7b35-44e6-9c84-8a9d2fc29eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Crear datos y estandarizacion de tipos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c58bb4f4-1429-4cf2-b893-e463439ea750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando carga para (2020-01-02 00:00:00 a 2025-12-12 00:00:00)\n"
     ]
    }
   ],
   "source": [
    "RAW_TABLE_NAME=os.getenv('RAW_TABLE_NAME')\n",
    "RAW_SCHEMA = os.getenv('RAW_SCHEMA') \n",
    "\n",
    "table_create_query = text(f\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS {RAW_SCHEMA}.{RAW_TABLE_NAME} (\n",
    "                    date DATE,\n",
    "                    ticker VARCHAR(20) NOT NULL,\n",
    "                    open DOUBLE PRECISION,\n",
    "                    high DOUBLE PRECISION,\n",
    "                    low DOUBLE PRECISION,\n",
    "                    close DOUBLE PRECISION,\n",
    "                    adj_close DOUBLE PRECISION,\n",
    "                    volume BIGINT,\n",
    "                    source_name VARCHAR(50),\n",
    "                    ingested_at_utc TIMESTAMP,\n",
    "                    run_id VARCHAR(50)\n",
    "                );\n",
    "            \"\"\")\n",
    "\n",
    "# Reintentos para asegurar existencia de la tabla\n",
    "print(f\"Iniciando carga para ({min_date} a {max_date})\")\n",
    "\n",
    "#Se mantienen los mismos retries\n",
    "for attempt in range(max_retries):\n",
    "    try:\n",
    "        with engine.begin() as conn:\n",
    "            conn.execute(text(f\"CREATE SCHEMA IF NOT EXISTS {RAW_SCHEMA};\"))\n",
    "            conn.execute(table_create_query)\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"Error al asegurar tabla (intento {attempt + 1}): {e}\")\n",
    "        time.sleep(5 * (attempt + 1))\n",
    "        if attempt == max_retries - 1:\n",
    "            raise  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb9d8b1-52dc-405d-806a-721a1331c639",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carga en postgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6a8dd46-dc89-4916-8ae8-2f66fc5dcee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos en raw.prices_daily\n",
      "Filas eliminadas previamente de IBM: 1006\n",
      "Filas insertadas: 1496\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cargando datos en {RAW_SCHEMA}.{RAW_TABLE_NAME}\")\n",
    "\n",
    "delete_query = text(f\"\"\"\n",
    "    DELETE FROM {RAW_SCHEMA}.{RAW_TABLE_NAME}\n",
    "    WHERE ticker = :ticker\n",
    "    AND date >= :min_date \n",
    "    AND date <= :max_date\n",
    "    \"\"\")   \n",
    "\n",
    "# Reintentos para inserción de datos\n",
    "for attempt in range(max_retries):\n",
    "    try:\n",
    "        with engine.begin() as conn:\n",
    "            # Limpiar datos previos\n",
    "            for current_ticker in TICKER.split(','):\n",
    "                result = conn.execute(delete_query, {\n",
    "                    'ticker': current_ticker,\n",
    "                    'min_date': min_date,\n",
    "                    'max_date': max_date\n",
    "                })\n",
    "                print(f\"Filas eliminadas previamente de {current_ticker}: {result.rowcount}\")\n",
    "\n",
    "        # Insertar nuevos datos\n",
    "        df_raw.to_sql(\n",
    "            name=RAW_TABLE_NAME,\n",
    "            con=engine,\n",
    "            schema=RAW_SCHEMA,\n",
    "            if_exists='append', # 'replace' si quieres borrar todo cada vez, 'append' para historial\n",
    "            index=False,\n",
    "            chunksize=1000 # Insertar por lotes para no saturar memoria\n",
    "        )\n",
    "        print(f\"Filas insertadas: {len(df_raw)}\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"Error durante la insercion (intento {attempt + 1}): {e}\")\n",
    "        # esperar antes de reintentar\n",
    "        time.sleep(5 * (attempt + 1))\n",
    "        if attempt == max_retries - 1:\n",
    "            raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd14b1b-8244-49dd-bee0-69769679552f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ece73735-13c2-4f69-a737-4cdc15533004",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "lxml not found, please install it",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m TICKER \u001b[38;5;129;01min\u001b[39;00m TICKERS\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      3\u001b[0m     ticker_obj \u001b[38;5;241m=\u001b[39m yf\u001b[38;5;241m.\u001b[39mTicker(TICKER)\n\u001b[0;32m----> 4\u001b[0m     earnings_df \u001b[38;5;241m=\u001b[39m \u001b[43mticker_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_earnings_dates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Trae los últimos 20 trimestres\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# yfinance devuelve la fecha en el índice con zona horaria, hay que limpiarlo\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     earnings_df\u001b[38;5;241m.\u001b[39mreset_index(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/yfinance/base.py:740\u001b[0m, in \u001b[0;36mTickerBase.get_earnings_dates\u001b[0;34m(self, limit, offset)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_earnings_dates\u001b[39m(\u001b[38;5;28mself\u001b[39m, limit \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12\u001b[39m, offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[pd\u001b[38;5;241m.\u001b[39mDataFrame]:\n\u001b[0;32m--> 740\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_earnings_dates_using_scrape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/yfinance/utils.py:92\u001b[0m, in \u001b[0;36mlog_indent_decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEntering \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m IndentationContext():\n\u001b[0;32m---> 92\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExiting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/yfinance/base.py:808\u001b[0m, in \u001b[0;36mTickerBase._get_earnings_dates_using_scrape\u001b[0;34m(self, limit, offset)\u001b[0m\n\u001b[1;32m    805\u001b[0m html_stringio \u001b[38;5;241m=\u001b[39m StringIO(table_html)\n\u001b[1;32m    807\u001b[0m \u001b[38;5;66;03m# Pass the StringIO object to pd.read_html()\u001b[39;00m\n\u001b[0;32m--> 808\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhtml_stringio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    810\u001b[0m \u001b[38;5;66;03m# Drop redundant columns\u001b[39;00m\n\u001b[1;32m    811\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSymbol\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompany\u001b[39m\u001b[38;5;124m\"\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/html.py:1212\u001b[0m, in \u001b[0;36mread_html\u001b[0;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links, dtype_backend)\u001b[0m\n\u001b[1;32m   1208\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[1;32m   1210\u001b[0m io \u001b[38;5;241m=\u001b[39m stringify_path(io)\n\u001b[0;32m-> 1212\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflavor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflavor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthousands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisplayed_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplayed_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextract_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1230\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/html.py:977\u001b[0m, in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m retained \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m flav \u001b[38;5;129;01min\u001b[39;00m flavor:\n\u001b[0;32m--> 977\u001b[0m     parser \u001b[38;5;241m=\u001b[39m \u001b[43m_parser_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflav\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    978\u001b[0m     p \u001b[38;5;241m=\u001b[39m parser(io, compiled_match, attrs, encoding, displayed_only, extract_links)\n\u001b[1;32m    980\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/html.py:934\u001b[0m, in \u001b[0;36m_parser_dispatch\u001b[0;34m(flavor)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _HAS_LXML:\n\u001b[0;32m--> 934\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlxml not found, please install it\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _valid_parsers[flavor]\n",
      "\u001b[0;31mImportError\u001b[0m: lxml not found, please install it"
     ]
    }
   ],
   "source": [
    "df_dates_all = pd.DataFrame()\n",
    "for TICKER in TICKERS.split(','):\n",
    "    ticker_obj = yf.Ticker(TICKER)\n",
    "    earnings_df = ticker_obj.get_earnings_dates(limit=20) # Trae los últimos 20 trimestres\n",
    "\n",
    "\n",
    "    # yfinance devuelve la fecha en el índice con zona horaria, hay que limpiarlo\n",
    "    earnings_df.reset_index(inplace=True)\n",
    "    earnings_df.rename(columns={'Earnings Date': 'earnings_date', 'EPS Estimate': 'eps_estimate', 'Reported EPS': 'reported_eps'}, inplace=True)\n",
    "\n",
    "    # Nos aseguramos de que sea solo fecha (sin hora) para cruzar con precios\n",
    "    earnings_df['earnings_date'] = pd.to_datetime(earnings_df['earnings_date']).dt.date\n",
    "    earnings_df['ticker'] = TICKER\n",
    "\n",
    "    # Solo nos importan las columnas clave\n",
    "    df_earnings_clean = earnings_df[['earnings_date', 'ticker', 'eps_estimate', 'reported_eps']].copy()\n",
    "    df_earnings_clean.head(10)\n",
    "\n",
    "    df_dates_all = pd.concat([df_dates_all, df_earnings_clean], ignore_index=True)\n",
    "\n",
    "df_dates_all.head(10)\n",
    "\n",
    "\n",
    "# Subir a postgres raw.earnings_dates\n",
    "table_name = 'earnings_dates'\n",
    "schema ='raw'\n",
    "print(f\"Cargando datos en {schema}.{table_name}\")\n",
    "# Reintentos para inserción de datos\n",
    "max_retries = 3\n",
    "for attempt in range(max_retries):\n",
    "    try:\n",
    "        # Insertar nuevos datos\n",
    "        df_dates_all.to_sql(\n",
    "            name=table_name,\n",
    "            con=engine,\n",
    "            schema=schema,\n",
    "            if_exists='replace', # 'replace' si quieres borrar todo cada vez, 'append' para historial\n",
    "            index=False,\n",
    "            chunksize=1000 # Insertar por lotes para no saturar memoria\n",
    "        )\n",
    "        print(f\"Filas insertadas: {len(df_dates_all)}\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"Error durante la insercion (intento {attempt + 1}): {e}\")\n",
    "        # esperar antes de reintentar\n",
    "        time.sleep(5 * (attempt + 1))\n",
    "        if attempt == max_retries - 1:\n",
    "            raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
