{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ede9f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar librerías necesarias (si no están en la imagen base)\n",
    "!pip install pandas yfinance psycopg2-binary lxml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e88854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from sqlalchemy import create_engine, text\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# DB Params\n",
    "PG_USER = os.getenv('PG_USER')\n",
    "PG_PASSWORD = os.getenv('PG_PASSWORD')\n",
    "PG_HOST = os.getenv('PG_HOST') \n",
    "PG_PORT = os.getenv('PG_PORT')\n",
    "PG_DB = os.getenv('PG_DB')\n",
    "\n",
    "# Business Params\n",
    "TICKERS = os.getenv('TICKERS')  \n",
    "START_DATE = os.getenv('START_DATE') \n",
    "END_DATE = os.getenv('END_DATE')\n",
    "\n",
    "# String de conexión SQLAlchemy\n",
    "db_url = f\"postgresql://{PG_USER}:{PG_PASSWORD}@{PG_HOST}:{PG_PORT}/{PG_DB}\"\n",
    "engine = create_engine(db_url)\n",
    "\n",
    "print(f\"Configuración cargada Rango={START_DATE} a {END_DATE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fd9253",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = []\n",
    "\n",
    "max_retries = 3\n",
    "\n",
    "for TICKER in TICKERS.split(','):\n",
    "    # Reintentos para descarga de datos\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            print(f\"Descargando datos para {TICKER}...\")\n",
    "            df_raw = yf.download(\n",
    "                tickers=TICKER, \n",
    "                start=START_DATE, \n",
    "                end=END_DATE, \n",
    "                interval='1d',\n",
    "                progress=False,\n",
    "                auto_adjust=False\n",
    "            )\n",
    "\n",
    "            # Asegurar que las columnas no sean MultiIndex\n",
    "            if isinstance(df_raw.columns, pd.MultiIndex):\n",
    "                df_raw.columns = df_raw.columns.get_level_values(0)\n",
    "\n",
    "            df_raw.reset_index(inplace=True)\n",
    "            # Añadir columna ticker\n",
    "            df_raw['ticker'] = TICKER\n",
    "\n",
    "            df_all.append(df_raw)\n",
    "            print(f\"Filas descargadas para {TICKER}: {len(df_raw)}\")\n",
    "            break  # si descarga ok, rompe el loop de reintentos\n",
    "        except Exception as e:\n",
    "            print(f\"Error al descargar {TICKER} (intento {attempt + 1}): {e}\")\n",
    "            time.sleep(5 * (attempt + 1))\n",
    "            if attempt == max_retries - 1:\n",
    "                print(f\"No se pudo descargar {TICKER} después de {max_retries} intentos.\")\n",
    "\n",
    "# Unir todos los DataFrames\n",
    "df_all = pd.concat(df_all, ignore_index=True)\n",
    "print(f\"Total filas descargadas: {len(df_all)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904919c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['ingested_at_utc'] = datetime.utcnow()\n",
    "df_all['run_id'] = datetime.now().strftime('run_%Y%m%d_%H%M')\n",
    "df_all['source_name'] = 'yahoo_finance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0423ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapping = {\n",
    "    'Date': 'date',\n",
    "    'Open': 'open',\n",
    "    'High': 'high',\n",
    "    'Low': 'low',\n",
    "    'Close': 'close',\n",
    "    'Adj Close': 'adj_close',\n",
    "    'Volume': 'volume'\n",
    "}\n",
    "df_all.rename(columns=column_mapping, inplace=True)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89622f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_date = df_all['date'].min()\n",
    "max_date = df_all['date'].max()\n",
    "\n",
    "\n",
    "table_name = 'prices_daily'\n",
    "schema = os.getenv('RAW_SCHEMA', 'raw')\n",
    "\n",
    "# Reintentos para asegurar existencia de la tabla\n",
    "print(f\"Iniciando carga para ({min_date} a {max_date})\")\n",
    "max_retries = 3\n",
    "for attempt in range(max_retries):\n",
    "    try:\n",
    "        print(f\"Asegurando existencia de tabla {schema}.{table_name}...\")\n",
    "        with engine.begin() as conn:\n",
    "            conn.execute(text(f\"CREATE SCHEMA IF NOT EXISTS {schema};\"))\n",
    "            conn.execute(text(f\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS {schema}.{table_name} (\n",
    "                    date DATE,\n",
    "                    ticker VARCHAR(20),\n",
    "                    open NUMERIC,\n",
    "                    high NUMERIC,\n",
    "                    low NUMERIC,\n",
    "                    close NUMERIC,\n",
    "                    adj_close NUMERIC,\n",
    "                    volume BIGINT,\n",
    "                    source_name VARCHAR(50),\n",
    "                    ingested_at_utc TIMESTAMP,\n",
    "                    run_id VARCHAR(50)\n",
    "                );\n",
    "            \"\"\"))\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"Error al asegurar tabla (intento {attempt + 1}): {e}\")\n",
    "        time.sleep(5 * (attempt + 1))\n",
    "        if attempt == max_retries - 1:\n",
    "            raise  \n",
    "    \n",
    "\n",
    "print(f\"Cargando datos en {schema}.{table_name}\")\n",
    "\n",
    "\n",
    "# Reintentos para inserción de datos\n",
    "for attempt in range(max_retries):\n",
    "    try:\n",
    "        with engine.begin() as conn:\n",
    "            # Limpiar datos previos para el mismo ticker y rango\n",
    "            delete_query = text(\"\"\"\n",
    "                DELETE FROM raw.prices_daily\n",
    "            WHERE ticker = :ticker\n",
    "            AND date >= :min_date \n",
    "            AND date <= :max_date\n",
    "            \"\"\"\n",
    "            )   \n",
    "            for current_ticker in TICKERS.split(','):\n",
    "                result = conn.execute(delete_query, {\n",
    "                    'ticker': current_ticker,\n",
    "                    'min_date': min_date,\n",
    "                    'max_date': max_date\n",
    "                })\n",
    "                print(f\"Filas eliminadas previamente de {current_ticker}: {result.rowcount}\")\n",
    "\n",
    "        # Insertar nuevos datos\n",
    "        df_all.to_sql(\n",
    "            name=table_name,\n",
    "            con=engine,\n",
    "            schema=schema,\n",
    "            if_exists='append', # 'replace' si quieres borrar todo cada vez, 'append' para historial\n",
    "            index=False,\n",
    "            chunksize=1000 # Insertar por lotes para no saturar memoria\n",
    "        )\n",
    "        print(f\"Filas insertadas: {len(df_all)}\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"Error durante la insercion (intento {attempt + 1}): {e}\")\n",
    "        # esperar antes de reintentar\n",
    "        time.sleep(5 * (attempt + 1))\n",
    "        if attempt == max_retries - 1:\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab9a81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dates_all = pd.DataFrame()\n",
    "for TICKER in TICKERS.split(','):\n",
    "    ticker_obj = yf.Ticker(TICKER)\n",
    "    earnings_df = ticker_obj.get_earnings_dates(limit=20) # Trae los últimos 20 trimestres\n",
    "\n",
    "\n",
    "    # yfinance devuelve la fecha en el índice con zona horaria, hay que limpiarlo\n",
    "    earnings_df.reset_index(inplace=True)\n",
    "    earnings_df.rename(columns={'Earnings Date': 'earnings_date', 'EPS Estimate': 'eps_estimate', 'Reported EPS': 'reported_eps'}, inplace=True)\n",
    "\n",
    "    # Nos aseguramos de que sea solo fecha (sin hora) para cruzar con precios\n",
    "    earnings_df['earnings_date'] = pd.to_datetime(earnings_df['earnings_date']).dt.date\n",
    "    earnings_df['ticker'] = TICKER\n",
    "\n",
    "    # Solo nos importan las columnas clave\n",
    "    df_earnings_clean = earnings_df[['earnings_date', 'ticker', 'eps_estimate', 'reported_eps']].copy()\n",
    "    df_earnings_clean.head(10)\n",
    "\n",
    "    df_dates_all = pd.concat([df_dates_all, df_earnings_clean], ignore_index=True)\n",
    "\n",
    "df_dates_all.head(10)\n",
    "\n",
    "\n",
    "# Subir a postgres raw.earnings_dates\n",
    "table_name = 'earnings_dates'\n",
    "schema = os.getenv('RAW_SCHEMA', 'raw')\n",
    "print(f\"Cargando datos en {schema}.{table_name}\")\n",
    "# Reintentos para inserción de datos\n",
    "max_retries = 3\n",
    "for attempt in range(max_retries):\n",
    "    try:\n",
    "        # Insertar nuevos datos\n",
    "        df_dates_all.to_sql(\n",
    "            name=table_name,\n",
    "            con=engine,\n",
    "            schema=schema,\n",
    "            if_exists='replace', # 'replace' si quieres borrar todo cada vez, 'append' para historial\n",
    "            index=False,\n",
    "            chunksize=1000 # Insertar por lotes para no saturar memoria\n",
    "        )\n",
    "        print(f\"Filas insertadas: {len(df_dates_all)}\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"Error durante la insercion (intento {attempt + 1}): {e}\")\n",
    "        # esperar antes de reintentar\n",
    "        time.sleep(5 * (attempt + 1))\n",
    "        if attempt == max_retries - 1:\n",
    "            raise"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
